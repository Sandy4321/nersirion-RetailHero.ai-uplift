{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift models и немного boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from All_Models import All_Models\n",
    "from Models_for_Predictions import Models_for_Predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываем путь к данным. В папке должны быть три датасета: features_trai.csv, features_val.csv, features_test.csv.\n",
    "Указываем столбцы, которое будут удаляться при активации моделей. При иницилизации класса, столбцы для удаления в \n",
    "тестовом датасете сформируются сами, но если во время работы добавяться новые столбцы, которые нужно удалять, то нужно\n",
    "добавить их в self.cols_to_drop и self.drop_columns_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/ML_Sets/data/'\n",
    "colsd = ['target', 'client_id', 'treatment_flg']\n",
    "uplift = Models_for_Predictions(cols_to_drop = colsd, path_to_files = path, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем функцию классифицирующую клиента по 4 классам, в зависимости от  treatment_flg и target\n",
    "uplift.create_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Меняем параметры в lgb модели, т.к. изначально стоят binary и auc\n",
    "uplift.lgb_params['objective'] = 'regression'\n",
    "uplift.lgb_params['metric'] = 'rmse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель, указывая нашу цель\n",
    "pred_class_train, pred_class_test = uplift.lgb_stacking('classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученые предсказания к нашим датасетам\n",
    "uplift.train['pred_class'] = pred_class_train\n",
    "uplift.test['pred_class'] = pred_class_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем класс с бинарной классификацией и фильтром по treatment_flg\n",
    "colsd = ['target', 'client_id', 'treatment_flg', 'classes']\n",
    "uplift1 = All_Models(cols_to_drop = colsd, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Передаем данные в новый класс\n",
    "uplift1.train = uplift.train\n",
    "uplift1.test = uplift.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель lgb\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = uplift1.start_training_lgb('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученные предсказания к данным\n",
    "uplift1.train['lgb_0_auc_1'] = predict_train_0\n",
    "uplift1.train['lgb_1_auc_1'] = predict_train_1\n",
    "uplift1.test['lgb_0_auc_1'] = np.asarray(predict_control).mean(axis=0)\n",
    "uplift1.test['lgb_1_auc_1'] = np.asarray(predict_treatment).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Меняем параметры модели lgb\n",
    "uplift1.lgb_params['objective'] = 'binary'\n",
    "uplift1.lgb_params['metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель lgb\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = tfd.start_training_lgb('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученные предсказания к данным\n",
    "uplift1.train['lgb_0_rmse_1'] = predict_train_0\n",
    "uplift1.train['lgb_1_rmse_1'] = predict_train_1\n",
    "uplift1.test['lgb_0_rmse_1'] = np.asarray(predict_control).mean(axis=0)\n",
    "uplift1.test['lgb_1_rmse_1'] = np.asarray(predict_treatment).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель cat\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = uplift1.start_training_cat('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученные предсказания к данным\n",
    "uplift1.train['cat_0_auc_1'] = predict_train_0\n",
    "uplift1.train['cat_1_auc_1'] = predict_train_1\n",
    "uplift1.test['cat_0_auc_1'] = np.asarray(predict_control).mean(axis=0)\n",
    "uplift1.test['cat_1_auc_1'] = np.asarray(predict_treatment).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два самых влиятельных признака transactions и avg_delay_beetwen_transc, поэтому попробовал создать новые признаки на их основе и полученных предсказаниях. Эти же признаки удалить, чтобы модели не зацикливались на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Составляем лист с полученными предсказаниями\n",
    "col_lists =['pred_class', 'lgb_0_auc_1', 'lgb_1_auc_1','lgb_0_rmse_1', 'lgb_1_rmse_1', 'cat_0_auc_1', 'cat_1_auc_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Генерируем новые признаки\n",
    "def new_features():\n",
    "    for col in col_lists:\n",
    "        uplift1.train[col+'*tran'] = uplift1.train[col]*uplift1.train['transactions']*0.1\n",
    "        uplift1.test[col+'*tran'] = uplift1.test[col]*uplift1.test['transactions']*0.1\n",
    "        uplift1.train[col+'/age'] = uplift1.train[col]/uplift1.train['age']\n",
    "        uplift1.test[col+'/age'] = uplift1.test[col]/uplift1.test['age']\n",
    "        uplift1.train[col+'/age*avg_tran_d'] = uplift1.train[col]/uplift1.train['age']*uplift1.train['avg_delay_beetwen_transc']\n",
    "        uplift1.test[col+'/age*avg_tran_d'] = uplift1.test[col]/uplift1.test['age']*uplift1.test['avg_delay_beetwen_transc']\n",
    "        \n",
    "new_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обновляем листы столбцов для удаления. \n",
    "cols_to_drop = ['treatment_flg', 'client_id', 'target', 'classes', 'transactions', 'avg_delay_beetwen_transc',]\n",
    "uplift1.cols_to_drop = cols_to_drop\n",
    "uplift1.drop_columns_test = ['client_id','transactions', 'avg_delay_beetwen_transc',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель lgb\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = uplift1.start_training_lgb('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученные данные\n",
    "uplift1.train['lgb_0_rmse_2'] = predict_train_0\n",
    "uplift1.train['lgb_1_rmse_2'] = predict_train_1\n",
    "uplift1.test['lgb_0_rmse_2'] = np.asarray(predict_control).mean(axis=0)\n",
    "uplift1.test['lgb_1_rmse_2'] = np.asarray(predict_treatment).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_lists =['pred_class', 'lgb_0_auc_1', 'lgb_1_auc_1','lgb_0_rmse_1', 'lgb_1_rmse_1', 'cat_0_auc_1', 'cat_1_auc_1',\\\n",
    "           'lgb_0_rmse_2', 'lgb_1_rmse_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Генерируем новые признаки\n",
    "new_features()\n",
    "uplift1.train['mean'] = uplift1.train.iloc[:, -36:].mean(axis=1)\n",
    "uplift1.train['sum'] = uplift1.train.iloc[:, -36:].sum(axis=1)\n",
    "uplift1.test['mean'] = uplift1.test.iloc[:, -36:].mean(axis=1)\n",
    "uplift1.test['sum'] = uplift1.test.iloc[:, -36:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем модель cat\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = uplift1.start_training_cat('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем полученные данные\n",
    "uplift1.train['cat_0_auc_2'] = predict_train_0\n",
    "uplift1.train['cat_1_auc_2'] = predict_train_1\n",
    "uplift1.test['cat_0_auc_2'] = np.asarray(predict_control).mean(axis=0)\n",
    "uplift1.test['cat_1_auc_2'] = np.asarray(predict_treatment).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Генерируем новые признаки\n",
    "new_features()\n",
    "uplift1.train['mean'] = uplift1.train.iloc[:, -39:].drop(['mean'], axis=1).mean(axis=1)\n",
    "uplift1.train['sum'] = uplift1.train.iloc[:, -39:].drop(['mean'], axis=1).sum(axis=1)\n",
    "uplift1.test['mean'] = uplift1.test.iloc[:, -39:].drop(['mean'], axis=1).mean(axis=1)\n",
    "uplift1.test['sum'] = uplift1.test.iloc[:, -39:].drop(['mean'], axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обновляем листы столбцов для удаления, добавляя \n",
    "cols_to_drop = ['treatment_flg', 'client_id', 'target', 'classes', 'transactions', 'avg_delay_beetwen_transc',\\\n",
    "               'pred_class*tran',] \n",
    "uplift1.cols_to_drop = cols_to_drop\n",
    "uplift1.drop_columns_test = ['client_id','transactions', 'avg_delay_beetwen_transc', 'pred_class*tran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем финальную модель lgb\n",
    "predict_control, predict_treatment, predict_train_0, predict_train_1, uplift_predict = uplift1.start_training_lgb('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняем предсказания\n",
    "uplift_submission = pd.DataFrame((uplift1.test['client_id'], uplift_predict)).T\n",
    "uplift_submission.columns = ['client_id', 'uplift']\n",
    "uplift_submission.to_csv('D:/ML_Sets/uplift_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P.S. Идеи и примечания\n",
    "\n",
    "1. Очень сильно колебался uplift_score в зависимости от гиперпараметров. Даже округлив базовые до сотых, которые получены из hyperopt (если что они были подогнаны совсем под другой датасет. Взял их за отправную точку просто) uplift score на val set падал на 0.003.\n",
    "\n",
    "\n",
    "2. hyperopt у меня не очень хотел работать с этими данными. Хотя я пробовал не долго, может стоит подождать 200+ evals. Плюс, думаю стоит попробовать его запускать именно под оптимизацию uplift score.\n",
    "\n",
    "\n",
    "3. Совсем модели не работают на цель 'treatment_flg'.\n",
    "\n",
    "\n",
    "4. В режиме low_memory отбрасываются признаки с товаров (level 1-4). Если их добавить, то может score улучшится.\n",
    "\n",
    "\n",
    "5. Была идея предсказывать сумму последней покупки. Гипотеза в том, что если клиент купил меньше, чем предсказывает модель, то какие-то товары он не нашел по скидке и стоит ему ее предложить.\n",
    "\n",
    "\n",
    "6. Найти и выбросить коррелирующие признаки.\n",
    "\n",
    "\n",
    "7. Побольше признаков сгенерировать из предсказаний. Например, cat_0 - lgb_1, lgb_0+cat_0 и т.д. \n",
    "\n",
    "\n",
    "8. Получше проработать признак transcations(количество покупок). Например, выбрасывая pred_class*tran из признаков score растет. Можно выкинуть еще часть признаков умноженных на transcations и score держится более менее, но если выкинуть все, то он падает ниже 0.05 на val set.\n",
    "\n",
    "\n",
    "9. Добавить цель target-treatment_flg, т.е. будет три класса: 1,0,-1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
